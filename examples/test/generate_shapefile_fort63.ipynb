{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31fdec1-1b22-4f83-bca1-221b5127e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#import Kalpana functions from github repository\n",
    "# change these to your own paths!\n",
    "sys.path.append('/Users/vivianhuang/Documents/GitHub/Kalpana')\n",
    "from kalpana.export import *\n",
    "from kalpana.visualizations import *\n",
    "import contextily as cx\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d25e2e4-8ad9-448e-b0c7-99e2a3edf233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    _FillValue: -99999.0\n",
      "    model: ADCIRC\n",
      "    version: v55.00-49-ga2c71f6\n",
      "    grid_type: Triangular\n",
      "    description: CTXCS_TP_0012_HIS                         ! 32 CHARACTER ALPHANUMERIC RUN DESCRI\n",
      "    agrid: Modified fort.14\n",
      "    rundes: CTXCS_TP_0012_HIS                         ! 32 CHARACTER ALPHANUMERIC RUN DESCRI\n",
      "    runid: Tides_1_SLC_0_RFC_0_WAV_1_GCP_CTX61LE02                          ! 24 CHARACTER\n",
      "    title: namo\n",
      "    institution: namo\n",
      "    source: namo\n",
      "    history: namo\n",
      "    references: namo\n",
      "    comments: namo\n",
      "    host: namo\n",
      "    convention: namo\n",
      "    Conventions: UGRID-0.9.0\n",
      "    contact: namo\n",
      "    creation_date: 2023-03-23 14:52:27 -05:00\n",
      "    modification_date: 2023-03-23 14:52:27 -05:00\n",
      "    fort.15: ==== Input File Parameters (below) ====\n",
      "    dt: 0.125\n",
      "    ihot: 0\n",
      "    ics: 2\n",
      "    nolibf: 1\n",
      "    nolifa: 2\n",
      "    nolica: 1\n",
      "    nolicat: 1\n",
      "    nwp: 7\n",
      "    ncor: 1\n",
      "    ntip: 0\n",
      "    nws: 0\n",
      "    nramp: 1\n",
      "    tau0: -3.0\n",
      "    statim: 0.0\n",
      "    reftim: 0.0\n",
      "    rnday: 4.0\n",
      "    dramp: 0.05\n",
      "    a00: 0.35\n",
      "    b00: 0.3\n",
      "    c00: 0.35\n",
      "    h0: 0.05\n",
      "    slam0: -93.37\n",
      "    sfea0: 29.000000000000004\n",
      "    cf: 0.00026\n",
      "    eslm: 4.0\n",
      "    cori: 0.0\n",
      "    ntif: 0\n",
      "    nbfr: 0\n",
      "    dimensions(sizes): time(384), node(62075), nele(122839), nvertex(3), nope(1), neta(125), max_nvdll(125), nbou(3), nvel(1196), max_nvell(493), mesh(1)\n",
      "    variables(dimensions): float64 time(time), float64 x(node), float64 y(node), int32 element(nele, nvertex), int32 adcirc_mesh(mesh), int32 neta(), int32 nvdll(nope), int32 max_nvdll(), int32 ibtypee(nope), int32 nbdv(neta), int32 nvel(), int32 nvell(nbou), int32 max_nvell(), int32 ibtype(nbou), int32 nbvv(nvel), float64 depth(node), float64 zeta(time, node)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "#plot the maximum water levels from a given maxele.63.nc file\n",
    "\n",
    "## path to netcdf file\n",
    "### netcdf is just a way to store datasets\n",
    "nc_path_2 = '/Users/vivianhuang/Documents/GitHub/Kalpana/examples/test/fort.63.nc' \n",
    "nc2 = netcdf.Dataset(nc_path_2, 'r')\n",
    "#check if this netcdf file looks right\n",
    "print(nc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9a6bd2-2622-4f28-92bf-06bb50a0418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExtractContours63(ncObj, var, levels, conType, epsg, stepLevel, orgMaxLevel, dzFile=None, zeroDif=-20,time_index=0):\n",
    "    ''' Run \"contours2gpd\" or \"filledContours2gpd\" if npro = 1 or \"contours2gpd_mp\" or \"filledContours2gpd_mp\" if npro > 1.\n",
    "        Parameters\n",
    "            ncObj: netCDF4._netCDF4.Dataset\n",
    "                Adcirc input file\n",
    "            var: string\n",
    "                Name of the variable to export\n",
    "            levels: np.array\n",
    "                Contour levels. The max value in the entire doman and over all timesteps is added to the requested levels.\n",
    "            conType: string\n",
    "                'polyline' or 'polygon'\n",
    "            epsg: int\n",
    "                coordinate system\n",
    "            stepLevel: int or float\n",
    "                step size of the levels requested\n",
    "            orgMaxLevel: int or float\n",
    "                max level requested\n",
    "            dzFile: str\n",
    "                full path of the pickle file with the vertical difference between datums\n",
    "                for each mesh node\n",
    "            zeroDif: int\n",
    "                threshold for using nearest neighbor interpolation to change datum. Points below\n",
    "                this value won't be changed.\n",
    "        Returns\n",
    "            gdf: GeoDataFrame\n",
    "                Polygons or polylines as geometry columns. If the requested file is time-varying the GeoDataFrame will include all timesteps.\n",
    "            \n",
    "    '''\n",
    "    ## get triangles and nodes coordinates\n",
    "    nv = ncObj['element'][:,:] - 1 ## triangles starts from 1\n",
    "    x = ncObj['x'][:].data\n",
    "    y = ncObj['y'][:].data\n",
    "    z = ncObj['depth'][:].data\n",
    "    \n",
    "    ## get extra info: variable name, variable long-name and unit name\n",
    "    vname = ncObj[var].name\n",
    "    lname = ncObj[var].long_name\n",
    "    #u = ncObj[var].units\n",
    "\n",
    "    ## matplotlib triangulation\n",
    "    tri = mpl.tri.Triangulation(x, y, nv)\n",
    "    \n",
    "    ## if the variable requested is the bathymetry, values are inverted (times -1) for plotting\n",
    "    if var == 'depth':\n",
    "        timeVar = 0\n",
    "        auxMult = -1\n",
    "    else:\n",
    "        auxMult = 1\n",
    "    \n",
    "    ## time constant\n",
    "\n",
    "    aux = ncObj[var][time_index][:].data\n",
    "    if dzFile != None: ## change datum\n",
    "        dfNewDatum = changeDatum(x, y, z, aux, dzFile, zeroDif)\n",
    "        ## change nan to -99999 and transform it to a 1D vector\n",
    "        aux = np.nan_to_num(dfNewDatum['newVar'].values, nan = -99999.0).reshape(-1)*auxMult\n",
    "    else: ## original datum remains constant\n",
    "        ## change nan to -99999 and transform it to a 1D vector\n",
    "        aux = np.nan_to_num(aux, nan = -99999.0).reshape(-1)*auxMult\n",
    "    ## non-filled contours\n",
    "    if conType == 'polyline':\n",
    "        labelCol = 'z'\n",
    "        gdf = contours2gpd(tri, aux, levels, epsg, True)\n",
    "    ## filled contours\n",
    "    elif conType == 'polygon':\n",
    "        labelCol = 'zMean'\n",
    "        gdf = filledContours2gpd(tri, aux, levels, epsg, stepLevel, orgMaxLevel, True)\n",
    "    ## error message\n",
    "    else:\n",
    "        print('only \"polyline\" and \"polygon\" types are supported!')\n",
    "        sys.exit(-1)\n",
    "    ## add more info to the geodataframe\n",
    "    gdf['variable'] = [vname]*len(gdf)\n",
    "    gdf['name'] = [lname]*len(gdf)\n",
    "        #gdf['zLabelCol'] = [f'{x:0.2f} {unit}' for x in gdf[labelCol]]        \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f0f535-467b-4970-a39a-3f1f98d947ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc2shp63(ncFile, var, levels, conType, pathOut, epsgOut, vUnitOut='ft', vUnitIn='m', epsgIn=4326,\n",
    "           subDomain=None, epsgSubDom=None, exportMesh=False, meshName=None, dzFile=None, zeroDif=-20,time_index=0):\n",
    "    ''' Run all necesary functions to export adcirc outputs as shapefiles.\n",
    "        Parameters\n",
    "            ncFile: string\n",
    "                path of the adcirc output, must be a netcdf file\n",
    "            var: string\n",
    "                Name of the variable to export\n",
    "            levels:list\n",
    "                Contour levels. Min, Max and Step. Max IS included as in np.arange method.\n",
    "                Values must be in vUnitOut vertical unit.\n",
    "            conType: string\n",
    "                'polyline' or 'polygon'\n",
    "            pathout: string\n",
    "                complete path of the output file (*.shp or *.gpkg)\n",
    "            epsgOut: int\n",
    "                coordinate system of the output shapefile\n",
    "            vUnitIn, vUnitOut: string. Default for vUnitIn is 'm' and 'ft' for vUnitOut\n",
    "                input and output vertical units. For the momment only supported 'm' and 'ft'\n",
    "            epsgIn: int. Default 4326.\n",
    "                coordinate system of the adcirc input\n",
    "            subDomain: str or list. Default None\n",
    "                complete path of the subdomain polygon kml or shapelfile, or list with the\n",
    "                uper-left x, upper-left y, lower-right x and lower-right y coordinates. The crs must be the same of the\n",
    "                adcirc input file.\n",
    "            exportMesh: boolean. Default False\n",
    "                True for export the mesh geodataframe and also save it as a shapefile\n",
    "            meshName: str\n",
    "                file name of the output mesh shapefile\n",
    "            dzFile: str\n",
    "                full path of the pickle file with the vertical difference between datums\n",
    "                for each mesh node\n",
    "            zeroDif: int\n",
    "                threshold for using nearest neighbor interpolation to change datum. Points below\n",
    "                this value won't be changed.\n",
    "        Returns\n",
    "            gdf: GeoDataFrame\n",
    "                gdf with contours\n",
    "            mesh: GeoDataFrame, only if exportMesh is True\n",
    "                gdf with mesh elements, representative length and area of each triangle\n",
    "    '''\n",
    "    \n",
    "    print('Start exporting adcirc to shape')\n",
    "    ## read adcirc file\n",
    "    nc = netcdf.Dataset(ncFile, 'r')\n",
    "    ## change units of the requested levels\n",
    "    if vUnitIn == 'm' and vUnitOut == 'ft':\n",
    "        levels = [l / 3.2808399 for l in levels]\n",
    "    elif vUnitIn == 'ft' and vUnitOut == 'm':\n",
    "        levels = [l * 3.2808399 for l in levels]\n",
    "    if conType == 'polygon':   \n",
    "        maxmax = np.max(nc[var][:].data)\n",
    "        orgMaxLevel = levels[1]\n",
    "        stepLevel = levels[2]\n",
    "        ## list of levels to array\n",
    "        levels_aux = np.arange(levels[0], np.ceil(maxmax), stepLevel)\n",
    "        ## given levels will now match the avarege value of each interval    \n",
    "        levels_aux = levels_aux - stepLevel/2\n",
    "        levels = levels_aux.copy()\n",
    "    else:\n",
    "        orgMaxLevel = levels[1]\n",
    "        stepLevel = levels[2]\n",
    "        levels = np.arange(levels[0], orgMaxLevel + stepLevel, stepLevel)\n",
    "    \n",
    "    t00 = time.time()\n",
    "    gdf = runExtractContours63(nc, var, levels, conType, epsgIn, stepLevel, orgMaxLevel, \n",
    "                            dzFile, zeroDif,time_index)\n",
    "    print(f'    Ready with the contours extraction: {(time.time() - t00)/60:0.3f} min')\n",
    "    \n",
    "    ## clip contours if requested\n",
    "    if subDomain is not None:\n",
    "        t0 = time.time()\n",
    "        subDom = readSubDomain(subDomain, epsgSubDom)\n",
    "        gdf = gpd.clip(gdf, subDom.to_crs(epsgIn))\n",
    "        print(f'    Cliping contours based on mask: {(time.time() - t0)/60:0.3f} min')\n",
    "    \n",
    "    ## change vertical units if requested\n",
    "    if vUnitIn == vUnitOut:\n",
    "        pass\n",
    "    else:\n",
    "        t0 = time.time()\n",
    "        gdf = gdfChangeVerUnit(gdf, vUnitIn, vUnitOut)\n",
    "        print(f'    Vertical units changed: {(time.time() - t0)/60:0.3f} min')\n",
    "    \n",
    "    ## change CRS if requested\n",
    "    if epsgIn == epsgOut:\n",
    "        pass\n",
    "    else:\n",
    "        t0 = time.time()\n",
    "        gdf = gdf.to_crs(epsgOut)\n",
    "        print(f'    Changing CRS: {(time.time() - t0)/60:0.3f} min')\n",
    "    \n",
    "    ## save output shape file\n",
    "    t0 = time.time()\n",
    "    if pathOut.endswith('.shp'):\n",
    "        gdf.to_file(pathOut)\n",
    "    elif pathOut.endswith('.gpkg'):\n",
    "        gdf.to_file(pathOut, driver = 'GPKG')\n",
    "    elif pathOut.endswith('.wkt'):\n",
    "        gdf.to_csv(pathOut)\n",
    "    print(f'    Saving file: {(time.time() - t0)/60:0.3f} min')\n",
    "    \n",
    "    ## export mesh if requested\n",
    "    if exportMesh == True:\n",
    "        print('    Exporting mesh')\n",
    "        t0 = time.time()\n",
    "        mesh = mesh2gdf(nc, epsgIn, epsgOut)\n",
    "        \n",
    "        if subDomain is not None:\n",
    "            mesh = gpd.clip(mesh, subDom.to_crs(epsgOut))\n",
    "        \n",
    "        mesh.to_file(os.path.join(os.path.dirname(pathOut), f'{meshName}.shp'))\n",
    "        print(f'    Mesh exported: {(time.time() - t0)/60:0.3f} min')\n",
    "        print(f'Ready with exporting code after: {(time.time() - t00)/60:0.3f} min')\n",
    "        return gdf, mesh\n",
    "    \n",
    "    else:\n",
    "        print(f'Ready with exporting code after: {(time.time() - t00)/60:0.3f} min')\n",
    "        return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18690161-0cf3-4767-b18a-99a5faeae022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path of the adcirc maxele output file, must be a netcdf file\n",
    "ncFile ='/Users/vivianhuang/Documents/GitHub/Kalpana/examples/test/fort.63.nc' \n",
    "\n",
    "## name of the maxele variable to downscale. Always 'zeta_max' for downscaling\n",
    "var = 'zeta'\n",
    "\n",
    "## Contour levels. Min, Max and Step. Max IS included as in np.arange method. Values must be in vUnitOut vertical unit.\n",
    "## from 0 to 3 meters (included) every 0.5\n",
    "levels = [-1, 19, 0.1]\n",
    "\n",
    "## 'polyline' or 'polygon'\n",
    "## we are creating polygons in this example\n",
    "conType = 'polygon'\n",
    "\n",
    "\n",
    "\n",
    "## coordinate system of the output shapefile\n",
    "epsgOut = 4326  # output in latitude and longitude, based on downscaling DEM\n",
    "\n",
    "## input and output vertical units. For the momment only supported 'm' and 'ft'  \n",
    "vUnitIn = 'm' ## Default 'm'\n",
    "vUnitOut = 'm' ## Default 'ft'\n",
    "\n",
    "## coordinate system of the adcirc input.\n",
    "## Default is 4326 since ADCIRC uses latitude and longitude\n",
    "epsgIn = 4326  \n",
    "\n",
    "## complete path of the subdomain polygon kml or shapelfile, or list with the\n",
    "## upper-left x, upper-left y, lower-right x and lower-right y coordinates. \n",
    "## the crs must be the same of the adcirc input file. \n",
    "subDomain = None  ## Default None\n",
    "\n",
    "## True for export the mesh geodataframe and also save it as a shapefile. \n",
    "## for this example we are only exporting the contours, not the mesh.\n",
    "exportMesh = False  ## Default False\n",
    "\n",
    "## file name of the output mesh shapefile. Default None\n",
    "meshName = None  ## Default None\n",
    "\n",
    "## full path of the pickle file with the vertical difference between datums for each mesh node. \n",
    "dzFile = None  ## Default None\n",
    "\n",
    "## threshold for using nearest neighbor interpolation to change datum. Points below this value won't be changed.\n",
    "zeroDif = -20  ## Default -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f302cbd2-1459-4eda-84a5-84b999b3b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_index = int(nc2['zeta'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bea4ebe-9c51-40f9-9db3-bcdfe5f8a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 84.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.022 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.025 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 81.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.020 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.023 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|█████████████| 89/89 [00:00<00:00, 108.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.016 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.018 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|█████████████| 89/89 [00:00<00:00, 100.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.017 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.019 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|█████████████| 89/89 [00:00<00:00, 112.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.015 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.017 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 81.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.021 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.023 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 80.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.021 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.023 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 80.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.021 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.023 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 84.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.020 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.022 min\n",
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [00:01<00:00, 78.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 0.021 min\n",
      "    Saving file: 0.002 min\n",
      "Ready with exporting code after: 0.023 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_index = 0\n",
    "#while time_index < max_time_index:\n",
    "while time_index < 10:\n",
    "    output_raster_dir = '/Users/vivianhuang/Desktop/mesh-try/time_index_'+str(time_index)+'/'\n",
    "    #output_raster_dir = '/Volumes/HDDLiting/neches_output/time_index_'+str(time_index)+'/'\n",
    "    if not os.path.exists(output_raster_dir):\n",
    "        os.makedirs(output_raster_dir)\n",
    "    \n",
    "    ## complete path of the output file (*.shp or *.gpkg)\n",
    "    pathOut = output_raster_dir+'neches_fort63.shp'\n",
    "    \n",
    "    \n",
    "    gdf = nc2shp63(ncFile, var, levels, conType, pathOut, epsgOut, vUnitOut=vUnitOut, vUnitIn=vUnitIn, epsgIn=epsgIn,\n",
    "               subDomain=subDomain, exportMesh=exportMesh, meshName=meshName, dzFile=dzFile, zeroDif=zeroDif,time_index=time_index)\n",
    "    time_index = time_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55516867-92b7-4e36-ab40-a48f52ff3596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start exporting adcirc to shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute contours using Dask: 100%|██████████████| 89/89 [01:10<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ready with the contours extraction: 1.176 min\n",
      "    Saving file: 0.030 min\n",
      "    Exporting mesh\n",
      "    Mesh exported: 0.122 min\n",
      "Ready with exporting code after: 1.329 min\n"
     ]
    }
   ],
   "source": [
    "time_index = 201\n",
    "#while time_index < max_time_index:\n",
    "while time_index < 202:\n",
    "    output_raster_dir = '/Users/vivianhuang/Desktop/mesh-try/'\n",
    "    #output_raster_dir = '/Volumes/HDDLiting/neches_output/time_index_'+str(time_index)+'/'\n",
    "    if not os.path.exists(output_raster_dir):\n",
    "        os.makedirs(output_raster_dir)\n",
    "    \n",
    "    ## complete path of the output file (*.shp or *.gpkg)\n",
    "    pathOut = output_raster_dir+'neches_fort63.shp'\n",
    "    \n",
    "    \n",
    "    gdf = nc2shp63(ncFile, var, levels, conType, pathOut, epsgOut, vUnitOut=vUnitOut, vUnitIn=vUnitIn, epsgIn=epsgIn,\n",
    "               subDomain=subDomain, exportMesh=exportMesh, meshName=meshName, dzFile=dzFile, zeroDif=zeroDif,time_index=time_index)\n",
    "    time_index = time_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c7bb63-4083-4af5-aff3-aea95dae9136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(max_time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d93b45-a227-4811-9ed5-10e4d9f8b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bb88a-e690-4729-9bbc-fc9a36ce7026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
